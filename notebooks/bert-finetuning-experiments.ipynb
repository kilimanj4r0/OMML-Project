{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT with different optimizers (non-clipped and clipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "[Yelp Reviews](https://huggingface.co/datasets/yelp_review_full) from HuggingFace\n",
    "\n",
    "Data Fields:\n",
    "- `text`: The review texts are escaped using double quotes (\"), and any internal double quote is escaped by 2 double quotes (\"\"). New lines are escaped by a backslash followed with an \"n\" character, that is \"\\n\".\n",
    "- `label`: Corresponds to the score associated with the review (between 1 and 5).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers\n",
    "\n",
    "- ✅ SGD\n",
    "- ✅ clipped-SGD\n",
    "- ✅ SGD (m=0.9)\n",
    "- ✅ clipped-SGD (m=0.9)\n",
    "- ✅ SGD-Nesterov (m=0.9)\n",
    "- ✅ clipped-SGD-Nesterov (m=0.9)\n",
    "- ✅ AdamW\n",
    "- ✅ clipped-AdamW\n",
    "- ❓ SSTM\n",
    "- ❓ clipped-SSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Code\n",
    "\n",
    "Taken from HuggingFace documentation, page [Fine-tune a pretrained model](https://huggingface.co/docs/transformers/training#train-in-native-pytorch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset yelp_review_full (C:/Users/newro/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5877067d6240af82f741b746ad11bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\newro\\.cache\\huggingface\\datasets\\yelp_review_full\\yelp_review_full\\1.0.0\\e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf\\cache-a26633295668fb09.arrow\n",
      "Loading cached processed dataset at C:\\Users\\newro\\.cache\\huggingface\\datasets\\yelp_review_full\\yelp_review_full\\1.0.0\\e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf\\cache-6adf2935a145f5cd.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\newro\\.cache\\huggingface\\datasets\\yelp_review_full\\yelp_review_full\\1.0.0\\e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf\\cache-f9e873cc15cd8bc2.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\newro\\.cache\\huggingface\\datasets\\yelp_review_full\\yelp_review_full\\1.0.0\\e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf\\cache-a3d5e7f693ef7708.arrow\n"
     ]
    }
   ],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_val_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\newro\\.cache\\huggingface\\datasets\\yelp_review_full\\yelp_review_full\\1.0.0\\e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf\\cache-a3d5e7f693ef7708.arrow\n"
     ]
    }
   ],
   "source": [
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(300, 800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)\n",
    "val_dataloader = DataLoader(small_val_dataset, shuffle=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim import SGD\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "# optimizer = SGD(model.parameters(), lr=5e-5)\n",
    "# optimizer = SGD(model.parameters(), lr=5e-5, nesterov=True, momentum=0.9)\n",
    "# optimizer = SGD(model.parameters(), lr=5e-5, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd55dc42b7014e578827ae56dd1ff445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011277777777609622, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\iu\\OMML-Project\\notebooks\\wandb\\run-20231217_151504-bujksppu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/makharev/iu-omml/runs/bujksppu' target=\"_blank\">stellar-elevator-12</a></strong> to <a href='https://wandb.ai/makharev/iu-omml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/makharev/iu-omml' target=\"_blank\">https://wandb.ai/makharev/iu-omml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/makharev/iu-omml/runs/bujksppu' target=\"_blank\">https://wandb.ai/makharev/iu-omml/runs/bujksppu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/makharev/iu-omml/runs/bujksppu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x27ba13fd290>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(entity=\"makharev\", project=\"iu-omml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde178ae259944eaa5a05e7138fb9a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import evaluate\n",
    "\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Add gradient clipping\n",
    "        clip_grad_norm_(model.parameters(), max_norm=1.0)  # L2-norm by default\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # Log loss to W&B\n",
    "        wandb.log({\"Training Loss\": loss.item()})\n",
    "\n",
    "        # Validation step\n",
    "        if progress_bar.n % len(train_dataloader) == 0:\n",
    "            model.eval()\n",
    "            metric = evaluate.load(\"accuracy\")\n",
    "            for val_batch in val_dataloader:\n",
    "                val_batch = {k: v.to(device) for k, v in val_batch.items()}\n",
    "                with torch.no_grad():\n",
    "                    val_outputs = model(**val_batch)\n",
    "\n",
    "                val_predictions = torch.argmax(val_outputs.logits, dim=-1)\n",
    "                metric.add_batch(predictions=val_predictions, references=val_batch[\"labels\"])\n",
    "\n",
    "            wandb.log({\"Validation Accuracy\": metric.compute()})\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9311ab39464405097c64004ed0b9e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.010 MB of 0.072 MB uploaded\\r'), FloatProgress(value=0.14235215946843854, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training Loss</td><td>█▇▂▅▇▅▆▂▅▂▅▆▇█▃▅▅▇▄▁▁▂▃▄▂▅▄▆▃▃▃▄▅▄▅▃▅▃▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training Loss</td><td>1.64688</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-elevator-12</strong> at: <a href='https://wandb.ai/makharev/iu-omml/runs/bujksppu' target=\"_blank\">https://wandb.ai/makharev/iu-omml/runs/bujksppu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_151504-bujksppu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "\n",
    "wandb.log({\"Evaluation Accuracy\": metric.compute()})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: If you are near downtown Las Vegas ( or have a car to drive there ) you must try these donuts. The Lemon is filled with the same tart lemon as a lemon bar. The Peach is filled with peach cream and topped with crumble. Can't wait to try the chocolate. Take these to friends, family or co - workers. One note - the entrance is on Carson not Sixth.\n",
      "True Label: 4, Predicted Label: 3\n",
      "Text: I have previously professed my Vegas burger love for Stripburger, but Holstein's come in a very respectable second to my favorite burger spot on the strip, if only for the price. Holstein's is a fairly new face on the strip, but it has already far exceeded Burger Bar and BLT Burger, among the plethora of other mediocre upscale burger joints on the strip. \\ n \\ nThe burgers are obviously top notch, and the creativity on some of the burgers is really refreshing ; more importantly, it's executed perfectly. There isn't really much else that needs to be said about the burgers at Holstein's, aside from try as many as possible, because they are all good. What separates Holstein's from the ever growing crowd of burger spots is their appetizers. The kimchi quesadillas, the philly cheese steak eggrolls, the incredible pork buns - there is no way to properly describe how good some of these appetizers are. And the kicker, at least for me, is that they are different. How many places, especially burger joints, serve kimchi quesadillas? As far as I can tell, not too many. The incredible creativity that is seen in the burger menu is also seen in the appetizers and the rest of the menu - and again, it's all executed flawlessly. I personally am not a big drinker, but I have tried one of their alcohol infused shakes, and it was delicious as well. \\ n \\ nThe service here is always great, but this place can get slammed in the evenings and the bar can get rather loud, especially if there is a big game on the TVs, so I would definitely recommend this as a lunch destination if possible. \\ n \\ nBottom line : if you're looking to spend a bit of money for a good burger, Holstein's should be your go to spot from here on out.\n",
      "True Label: 3, Predicted Label: 3\n",
      "Text: Disappointing. The only thing that wasn't disappointing was our server and the person I went with. ( so they each got a star ) We had the chopped salad. Nothing on it was chopped. Why call it a chopped salad? I have done kitchen prep before so I know that this plate was sitting with friends on a tray in the fridge until our server went to go get it. It was not fresh lettuce. It was white, hard, some brown, old pathetic lettuce. We shared a pizza which he said he would have cut into 6 pieces and it wasn't. Pizza was unremarkable. Didn't ask us if we wanted dessert. If you are a server a piece of advice is ALWAYS ASK!!! If we say yes, then that's MORE TIP FOR YOU! I went once before to the Norterra location with my husband and I love me a soft pretzel so I was looking forward to trying theirs. I'm from Philly so we are used to pretzels which are sold everywhere ( on the street corners to the airport ) in sets of three, in a brown paper bag. Theirs was pizza dough in the shape of a pretzel. Hmm. No. The pretzels at Brat Haus were WAAAAAAY better. I probably will not go back.\n",
      "True Label: 1, Predicted Label: 0\n",
      "Text: After waiting on the phone as \\ \" caller number one \\ \" for almost 10 mins, I decided to drive in while still on hold... After getting parked and in line the casket FINALLY picked up my call. I ordered my food only to get home and it was WRONG. Avoid this location at all cost, I can't believe they screwed up my meal after all that.\n",
      "True Label: 0, Predicted Label: 0\n",
      "Text: Whatever you do - no matter how hard they ask - do NOT give these people your phone number and ESPECIALLY don't give them your email address. They are spam kings. They have been spamming me for YEARS - no matter how hard I try they never give up. They have no customer service. They are the typical sleazy used car types. The spam is unrelenting. You have been forewarned. If you feel the need to give them an email address, use a fake address or one that you don't care about monitoring because they WILL absolutely, relentlessly, for YEARS email you. No matter what.\n",
      "True Label: 0, Predicted Label: 0\n",
      "Text: My husband and I own a timeshare and decided to trade it in for staying at the Grand Chateau. I had read reviews that there was construction going on, but when we went, they were working on the inside of the rooms so we never had any noise issues. \\ n \\ nThe location is great! It's located on the southern side of the Strip right by the Miracle Shops / Planet Holleywood. They have a shuttle service that'll get you about mid - strip and drop you off at the Fashion Mall which would often times spare our feet. \\ n \\ nThe rooms were lovely. Granite counter tops, copper sinks, jacuzzi tub, duel shower heads, flat screen tv, I seriously couldnt complain. The wifi was really shoddy, but I was able to get online and make reservations while we stayed there. \\ n \\ nThey dont have a casino and are 100 % smoke free which is awesome because I cant STAND the smell of cigs and it's nice to get away from the hustle and bustle of the strip and lay your head down to peace and quiet. \\ n \\ nThey have a small convenient store with overpriced items, but sometimes when you dont want to make the walk, it's nice to have one there. We didnt check out the pool as it was Feb when we went and much too cold so I cant comment on that. Service was always excellent and we'd DEFINITELY stay here again!\n",
      "True Label: 4, Predicted Label: 3\n",
      "Text: Check out my review and photos : \\ n \\ nhttp : / / food - tales - and - other - fun. tumblr. com / post / 29865866478 /\n",
      "True Label: 3, Predicted Label: 3\n",
      "Text: Had AYCE lunch here. We were promptly seated and served drinks. Appetizers came out quick. Our rolls were very large and nice looking. The staff was very pleasant and quick to check on us. Plenty of rolls to choose from. Can be a bit slow as there was only one chef while we were here. Look forward to coming back.\n",
      "True Label: 3, Predicted Label: 2\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "texts = []\n",
    "\n",
    "for test_batch in eval_dataloader:\n",
    "    test_batch = {k: v.to(device) for k, v in test_batch.items()}\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(**test_batch)\n",
    "\n",
    "    test_logits = test_outputs.logits\n",
    "    test_predictions = torch.argmax(test_logits, dim=-1)\n",
    "    predictions.extend(test_predictions.cpu().numpy())\n",
    "    true_labels.extend(test_batch[\"labels\"].cpu().numpy())\n",
    "    texts.extend(tokenizer.batch_decode(test_batch[\"input_ids\"], skip_special_tokens=True))\n",
    "    break\n",
    "\n",
    "for true_label, predicted_label, text in zip(true_labels, predictions, texts):\n",
    "    print(f\"Text: {text}\\nTrue Label: {true_label}, Predicted Label: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
